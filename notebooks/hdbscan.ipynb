{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7397746616854031\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tests for HDBSCAN clustering algorithm\n",
    "Shamelessly based on (i.e. ripped off from) the DBSCAN test code\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils._testing import (\n",
    "    assert_array_equal,\n",
    "    assert_array_almost_equal,\n",
    "    assert_raises,\n",
    ")\n",
    "from hdbscan import (\n",
    "    HDBSCAN,\n",
    "    hdbscan,\n",
    "    validity_index,\n",
    "    approximate_predict,\n",
    "    approximate_predict_scores,\n",
    "    membership_vector,\n",
    "    all_points_membership_vectors,\n",
    ")\n",
    "\n",
    "# from sklearn.cluster.tests.common import generate_clustered_data\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import mode\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "from functools import wraps\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import warnings\n",
    "\n",
    "n_clusters = 3\n",
    "# X = generate_clustered_data(n_clusters=n_clusters, n_samples_per_cluster=50)\n",
    "X, y = make_blobs(n_samples=200, random_state=10)\n",
    "X, y = shuffle(X, y, random_state=7)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_missing_data = X.copy()\n",
    "X_missing_data[0] = [np.nan, 1]\n",
    "X_missing_data[5] = [np.nan, np.nan]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hdbscan_distance_matrix():\n",
    "    D = distance.squareform(distance.pdist(X))\n",
    "    D /= np.max(D)\n",
    "\n",
    "    labels, p, persist, ctree, ltree, mtree = hdbscan(D, metric=\"precomputed\")\n",
    "    # number of clusters, ignoring noise if present\n",
    "    n_clusters_1 = len(set(labels)) - int(-1 in labels)  # ignore noise\n",
    "    assert n_clusters_1 == n_clusters\n",
    "\n",
    "    labels = HDBSCAN(metric=\"precomputed\").fit(D).labels_\n",
    "    n_clusters_2 = len(set(labels)) - int(-1 in labels)\n",
    "    assert n_clusters_2 == n_clusters\n",
    "\n",
    "    validity = validity_index(D, labels, metric=\"precomputed\", d=2)\n",
    "    print(validity)\n",
    "    assert validity >= 0.6\n",
    "\n",
    "test_hdbscan_distance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7397746616854026\n"
     ]
    }
   ],
   "source": [
    "def test_hdbscan_feature_vector():\n",
    "    labels, p, persist, ctree, ltree, mtree = hdbscan(X)\n",
    "    n_clusters_1 = len(set(labels)) - int(-1 in labels)\n",
    "    assert n_clusters_1 == n_clusters\n",
    "\n",
    "    labels = HDBSCAN().fit(X).labels_\n",
    "    n_clusters_2 = len(set(labels)) - int(-1 in labels)\n",
    "    assert n_clusters_2 == n_clusters\n",
    "\n",
    "    validity = validity_index(X, labels)\n",
    "    print(validity)\n",
    "    assert validity >= 0.4\n",
    "\n",
    "test_hdbscan_feature_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3298585 , 2.58787844, ..., 3.13096099, 0.45522349,\n",
       "        2.94719999],\n",
       "       [0.3298585 , 0.        , 2.68891822, ..., 3.10298371, 0.57490871,\n",
       "        2.99872532],\n",
       "       [2.58787844, 2.68891822, 0.        , ..., 1.2263978 , 3.02582596,\n",
       "        0.54685975],\n",
       "       ...,\n",
       "       [3.13096099, 3.10298371, 1.2263978 , ..., 0.        , 3.58460062,\n",
       "        0.74819803],\n",
       "       [0.45522349, 0.57490871, 3.02582596, ..., 3.58460062, 0.        ,\n",
       "        3.39799078],\n",
       "       [2.94719999, 2.99872532, 0.54685975, ..., 0.74819803, 3.39799078,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.squareform(distance.pdist(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance.squareform()\n",
    "D = distance.squareform(distance.pdist([[0,0],[1,1], [2,2]]))\n",
    "D /= np.max(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. ],\n",
       "       [0.5, 0. , 0.5],\n",
       "       [1. , 0.5, 0. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.41421356, 1.        , 1.        , 1.41421356,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.pdist([[0,0],[0,1], [1,1],[1,0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
