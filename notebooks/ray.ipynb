{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from PIL.Image import Image\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.data.datasource.partitioning import Partitioning\n",
    "from ray.data.preprocessors import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformTypes = Optional[Union[A.Compose, T.Compose]]\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 0.003\n",
    "TRAIN_DATA_PATH = \"../data/train/\"\n",
    "TEST_DATA_PATH = \"../data/val/\"\n",
    "\n",
    "\n",
    "TRANSFORM_IMG = T.Compose(\n",
    "    [\n",
    "        T.Resize(224),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = torchvision.datasets.ImageFolder(\n",
    "#     root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG\n",
    "# )\n",
    "# train_data_loader = torch.utils.data.DataLoader(\n",
    "#     train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4\n",
    "# )\n",
    "# test_data = torchvision.datasets.ImageFolder(\n",
    "#     root=TEST_DATA_PATH, transform=TRANSFORM_IMG\n",
    "# )\n",
    "# test_data_loader = torch.utils.data.DataLoader(\n",
    "#     test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:15:43,055\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG\n",
    ")\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=TEST_DATA_PATH, transform=TRANSFORM_IMG\n",
    ")\n",
    "\n",
    "train_dataset: ray.data.Dataset = ray.data.from_torch(train_dataset)\n",
    "test_dataset: ray.data.Dataset = ray.data.from_torch(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_partitioning = Partitioning(\n",
    "#     \"dir\", field_names=[\"label\"], base_dir=TRAIN_DATA_PATH\n",
    "# )\n",
    "# train_dataset = ray.data.read_images(\n",
    "#     TRAIN_DATA_PATH, size=(224, 224), partitioning=train_partitioning\n",
    "# )\n",
    "# test_partitioning = Partitioning(\"dir\", field_names=[\"label\"], base_dir=TEST_DATA_PATH)\n",
    "# test_dataset = ray.data.read_images(\n",
    "#     TEST_DATA_PATH, size=(224, 224), partitioning=test_partitioning\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2996 MiB, 201 objects, write throughput 2357 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    }
   ],
   "source": [
    "# encoder = LabelEncoder(label_column=\"label\")\n",
    "# encoder.fit_transform(train_dataset)\n",
    "# encoder.transform(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:15:48,129\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "MapBatches(convert_batch_to_numpy):   8%|▊         | 17/201 [00:15<01:55,  1.60it/s]\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 5060 MiB, 356 objects, write throughput 2350 MiB/s.\n",
      "MapBatches(convert_batch_to_numpy): 100%|██████████| 201/201 [00:16<00:00, 12.38it/s]\n",
      "2023-03-17 14:16:04,459\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "MapBatches(convert_batch_to_numpy): 100%|██████████| 16/16 [00:00<00:00, 339.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_batch_to_numpy(batch: Tuple[Image, int]) -> Dict[str, np.ndarray]:\n",
    "    images = np.stack([np.array(image) for image, _ in batch])\n",
    "    labels = np.array([label for _, label in batch])\n",
    "    return {\"image\": images, \"label\": labels}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map_batches(convert_batch_to_numpy).fully_executed()\n",
    "test_dataset = test_dataset.map_batches(convert_batch_to_numpy).fully_executed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[[-0.01155927,  0.00556549, -0.08005828, ...,  0.31381115,\n",
      "          0.33093593,  0.33093593],\n",
      "        [-0.02868402, -0.04580877, -0.06293353, ...,  0.33093593,\n",
      "          0.33093593,  0.31381115],\n",
      "        [-0.06293353, -0.04580877, -0.06293353, ...,  0.3651854 ,\n",
      "          0.3651854 ,  0.34806067],\n",
      "        ...,\n",
      "        [-2.0151556 , -1.7754089 , -1.5870366 , ..., -1.1246684 ,\n",
      "         -1.3472902 , -1.5014129 ],\n",
      "        [-2.0322802 , -1.7925336 , -1.6212862 , ..., -1.1589178 ,\n",
      "         -1.3815396 , -1.5185376 ],\n",
      "        [-2.0494049 , -1.6384109 , -1.5699118 , ..., -1.1760426 ,\n",
      "         -1.3815396 , -1.5356624 ]],\n",
      "\n",
      "       [[ 0.11764706,  0.13515405,  0.04761905, ...,  0.45028022,\n",
      "          0.4677872 ,  0.4677872 ],\n",
      "        [ 0.10014006,  0.08263306,  0.06512605, ...,  0.4677872 ,\n",
      "          0.4677872 ,  0.45028022],\n",
      "        [ 0.06512605,  0.08263306,  0.06512605, ...,  0.50280124,\n",
      "          0.50280124,  0.48529422],\n",
      "        ...,\n",
      "        [-1.9306722 , -1.6855742 , -1.4929972 , ..., -1.0203081 ,\n",
      "         -1.247899  , -1.405462  ],\n",
      "        [-1.9481792 , -1.7030813 , -1.5280112 , ..., -1.055322  ,\n",
      "         -1.2829131 , -1.4229691 ],\n",
      "        [-1.9656862 , -1.5455182 , -1.4754901 , ..., -1.0728291 ,\n",
      "         -1.2829131 , -1.4404761 ]],\n",
      "\n",
      "       [[ 0.33934647,  0.35677567,  0.2696297 , ...,  0.6705013 ,\n",
      "          0.68793046,  0.68793046],\n",
      "        [ 0.32191727,  0.3044881 ,  0.2870589 , ...,  0.68793046,\n",
      "          0.68793046,  0.6705013 ],\n",
      "        [ 0.2870589 ,  0.3044881 ,  0.2870589 , ...,  0.7227889 ,\n",
      "          0.7227889 ,  0.70535964],\n",
      "        ...,\n",
      "        [-1.6998693 , -1.4558606 , -1.2641394 , ..., -0.79355115,\n",
      "         -1.0201306 , -1.1769934 ],\n",
      "        [-1.7172985 , -1.4732897 , -1.2989979 , ..., -0.82840955,\n",
      "         -1.0549891 , -1.1944225 ],\n",
      "        [-1.7347276 , -1.316427  , -1.2467101 , ..., -0.8458387 ,\n",
      "         -1.0549891 , -1.2118517 ]]], dtype=float32), 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "test_dataset.show(1)#[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# Image.fromarray(test_dataset.take(1)[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 7 * 7, 120),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:16:04,698\tINFO instantiator.py:21 -- Created a temporary directory at /var/folders/p4/kcmtkxw53z54k341vwwykts80000gn/T/tmpeena33u7\n",
      "2023-03-17 14:16:04,699\tINFO instantiator.py:76 -- Writing /var/folders/p4/kcmtkxw53z54k341vwwykts80000gn/T/tmpeena33u7/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    model = train.torch.prepare_model(Net(num_classes=2))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        train_dataset_batches = train_dataset_shard.iter_torch_batches(\n",
    "            batch_size=config[\"batch_size\"], device=train.torch.get_device()\n",
    "        )\n",
    "        for i, batch in enumerate(train_dataset_batches):\n",
    "            # get the inputs and labels\n",
    "            inputs, labels = batch[\"image\"], batch[\"label\"]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        metrics = dict(running_loss=running_loss)\n",
    "        checkpoint = TorchCheckpoint.from_state_dict(model.state_dict())\n",
    "        session.report(metrics, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.data.preprocessors import TorchVisionPreprocessor\n",
    "\n",
    "# preprocessor = TorchVisionPreprocessor(columns=[\"image\"], transform=TRANSFORM_IMG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-17 14:16:07</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:02.32        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.3/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 3.0/10 CPUs, 0/0 GPUs, 0.0/4.85 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_32a86_00000</td><td>RUNNING </td><td>127.0.0.1:15275</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=15275)\u001b[0m 2023-03-17 14:16:09,203\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15276)\u001b[0m 2023-03-17 14:16:09,184\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=15275)\u001b[0m /opt/homebrew/Caskroom/miniforge/base/envs/xnn/lib/python3.10/site-packages/ray/data/_internal/bulk_dataset_iterator.py:108: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=15275)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15276)\u001b[0m 2023-03-17 14:16:10,356\tINFO train_loop_utils.py:255 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15276)\u001b[0m 2023-03-17 14:16:10,357\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  running_loss</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_32a86_00000</td><td style=\"text-align: right;\">            26.5209</td><td style=\"text-align: right;\">  1679033815</td><td style=\"text-align: right;\">                    2</td><td>2023-03-17_14-16-55</td><td>False </td><td>                </td><td>7286415d5e604a12be5ea19ec1342106</td><td>mac.local </td><td style=\"text-align: right;\">                         2</td><td>127.0.0.1</td><td style=\"text-align: right;\">15275</td><td style=\"text-align: right;\">       367.159</td><td>True               </td><td style=\"text-align: right;\">             48.1177</td><td style=\"text-align: right;\">           26.5227</td><td style=\"text-align: right;\">       48.1177</td><td style=\"text-align: right;\"> 1679033815</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>32a86_00000</td><td style=\"text-align: right;\">    0.0846431</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:16:57,305\tINFO tune.py:798 -- Total run time: 52.53 seconds (52.51 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "use_gpu = ray.available_resources().get(\"GPU\", 0) >= 2\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"batch_size\": 2},\n",
    "    datasets={\"train\": train_dataset},\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=use_gpu),\n",
    "    # preprocessor=preprocessor,\n",
    ")\n",
    "result = trainer.fit()\n",
    "latest_checkpoint = result.checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:16:57,350\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(ScoringWrapper)]\n",
      "MapBatches(ScoringWrapper), 0 actors:   6%|▋         | 1/16 [00:01<00:27,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(\n",
    "    checkpoint=latest_checkpoint,\n",
    "    predictor_cls=TorchPredictor,\n",
    "    model=Net(num_classes=2),\n",
    ")\n",
    "\n",
    "outputs: ray.data.Dataset = batch_predictor.predict(\n",
    "    data=test_dataset,\n",
    "    dtype=torch.float,\n",
    "    feature_columns=[\"image\"],\n",
    "    keep_columns=[\"label\"],\n",
    "    # We will use GPU if available.\n",
    "    num_gpus_per_worker=ray.available_resources().get(\"GPU\", 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:16:59,212\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_logits_to_classes)]\n",
      "MapBatches(convert_logits_to_classes): 100%|██████████| 1/1 [00:00<00:00, 114.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 0, 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def convert_logits_to_classes(df):\n",
    "    best_class = df[\"predictions\"].map(lambda x: x.argmax())\n",
    "    df[\"prediction\"] = best_class\n",
    "    return df[[\"prediction\", \"label\"]]\n",
    "\n",
    "\n",
    "predictions = outputs.map_batches(convert_logits_to_classes)\n",
    "\n",
    "predictions.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:16:59,251\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(calculate_prediction_scores)]\n",
      "MapBatches(calculate_prediction_scores): 100%|██████████| 1/1 [00:00<00:00, 215.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 0, 'label': 0, 'correct': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_prediction_scores(df):\n",
    "    df[\"correct\"] = df[\"prediction\"] == df[\"label\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "scores = predictions.map_batches(calculate_prediction_scores)\n",
    "\n",
    "scores.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 14:16:59,281\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[aggregate]\n",
      "Shuffle Map: 100%|██████████| 1/1 [00:00<00:00, 130.60it/s]\n",
      "Shuffle Reduce: 100%|██████████| 1/1 [00:00<00:00, 214.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sum(on=\"correct\") / scores.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=15295)\u001b[0m INFO 2023-03-17 14:17:00,042 controller 15295 http_state.py:129 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-c8e692bf02bc194459e2ad8b498820ed92bde5060beda79e4bcec9f4' on node 'c8e692bf02bc194459e2ad8b498820ed92bde5060beda79e4bcec9f4' listening on '127.0.0.1:8000'\n",
      "2023-03-17 14:17:00,723\tINFO api.py:254 -- Started detached Serve instance in namespace \"serve\".\n",
      "2023-03-17 14:17:00,741\tINFO client.py:540 -- Updating deployment 'PredictorDeployment'. component=serve deployment=PredictorDeployment\n",
      "\u001b[2m\u001b[36m(ServeController pid=15295)\u001b[0m INFO 2023-03-17 14:17:00,781 controller 15295 deployment_state.py:1333 - Adding 1 replica to deployment 'PredictorDeployment'.\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=15296)\u001b[0m INFO:     Started server process [15296]\n",
      "2023-03-17 14:17:02,761\tINFO client.py:555 -- Deployment 'PredictorDeployment' is ready at `http://127.0.0.1:8000/`. component=serve deployment=PredictorDeployment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='PredictorDeployment')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import serve\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import json_to_ndarray\n",
    "\n",
    "\n",
    "serve.run(\n",
    "    PredictorDeployment.bind(\n",
    "        TorchPredictor,\n",
    "        latest_checkpoint,\n",
    "        model=Net(num_classes=2),\n",
    "        http_adapter=json_to_ndarray,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_dataset.take(1)[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0.3135456144809723, -0.3151269555091858]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=15296)\u001b[0m INFO 2023-03-17 14:17:03,149 http_proxy 127.0.0.1 http_proxy.py:373 - POST / 200 124.9ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:PredictorDeployment pid=15297)\u001b[0m INFO 2023-03-17 14:17:03,147 PredictorDeployment PredictorDeployment#RUznkJ replica.py:518 - HANDLE __call__ OK 117.3ms\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "payload = {\"array\": image.tolist(), \"dtype\": \"float32\"}\n",
    "response = requests.post(\"http://localhost:8000/\", json=payload)\n",
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
