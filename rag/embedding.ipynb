{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.50494384765625, 64.03975677490234, 19.520008087158203]]\n"
     ]
    }
   ],
   "source": [
    "# Requires transformers>=4.36.0\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "input_texts = [\n",
    "    \"what is the capital of China?\",\n",
    "    \"how to implement quick sort in python?\",\n",
    "    \"Beijing\",\n",
    "    \"sorting algorithms\",\n",
    "]\n",
    "\n",
    "model_path = \"Alibaba-NLP/gte-base-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(\n",
    "    input_texts, max_length=8192, padding=True, truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = outputs.last_hidden_state[:, 0]\n",
    "\n",
    "# (Optionally) normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
    "print(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.72777176 0.6808348 ]\n",
      " [0.72777176 0.9999999  0.7170707 ]\n",
      " [0.6808348  0.7170707  1.        ]]\n",
      "[0.6533682 0.5988234 0.7237106]\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"avsolatorio/NoInstruct-small-Embedding-v0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avsolatorio/NoInstruct-small-Embedding-v0\")\n",
    "\n",
    "\n",
    "def get_embedding(text: Union[str, list[str]], mode: str = \"sentence\"):\n",
    "    model.eval()\n",
    "\n",
    "    assert mode in (\"query\", \"sentence\"), f\"mode={mode} was passed but only `query` and `sentence` are the supported modes.\"\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "\n",
    "    inp = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inp)\n",
    "\n",
    "    # The model is optimized to use the mean pooling for queries,\n",
    "    # while the sentence / document embedding uses the [CLS] representation.\n",
    "\n",
    "    if mode == \"query\":\n",
    "        vectors = output.last_hidden_state * inp[\"attention_mask\"].unsqueeze(2)\n",
    "        vectors = vectors.sum(dim=1) / inp[\"attention_mask\"].sum(dim=-1).view(-1, 1)\n",
    "    else:\n",
    "        vectors = output.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return vectors\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Illustration of the REaLTabFormer model. The left block shows the non-relational tabular data model using GPT-2 with a causal LM head. In contrast, the right block shows how a relational dataset's child table is modeled using a sequence-to-sequence (Seq2Seq) model. The Seq2Seq model uses the observations in the parent table to condition the generation of the observations in the child table. The trained GPT-2 model on the parent table, with weights frozen, is also used as the encoder in the Seq2Seq model.\",\n",
    "    \"Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility.\",\n",
    "    \"As the economies of Southeast Asia continue adopting digital technologies, policy makers increasingly ask how to prepare the workforce for emerging labor demands. However, little is known about the skills that workers need to adapt to these changes\"\n",
    "]\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = get_embedding(texts, mode=\"sentence\")\n",
    "\n",
    "# Compute cosine-similarity for each pair of sentences\n",
    "scores = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "print(scores.cpu().numpy())\n",
    "\n",
    "# Test the retrieval performance.\n",
    "query = get_embedding(\"Which sentence talks about concept on jobs?\", mode=\"query\")\n",
    "\n",
    "scores = F.cosine_similarity(query, embeddings, dim=-1)\n",
    "print(scores.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001  0.6846288  0.61258197]\n",
      " [0.6846288  1.         0.6557728 ]\n",
      " [0.61258197 0.6557728  1.        ]]\n",
      "[0.606564   0.5516183  0.69535196]\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"avsolatorio/GIST-small-Embedding-v0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avsolatorio/GIST-small-Embedding-v0\")\n",
    "\n",
    "\n",
    "def get_embedding(text: Union[str, list[str]], mode: str = \"sentence\"):\n",
    "    model.eval()\n",
    "\n",
    "    assert mode in (\"query\", \"sentence\"), f\"mode={mode} was passed but only `query` and `sentence` are the supported modes.\"\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "\n",
    "    inp = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inp)\n",
    "\n",
    "    # The model is optimized to use the mean pooling for queries,\n",
    "    # while the sentence / document embedding uses the [CLS] representation.\n",
    "\n",
    "    if mode == \"query\":\n",
    "        vectors = output.last_hidden_state * inp[\"attention_mask\"].unsqueeze(2)\n",
    "        vectors = vectors.sum(dim=1) / inp[\"attention_mask\"].sum(dim=-1).view(-1, 1)\n",
    "    else:\n",
    "        vectors = output.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return vectors\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Illustration of the REaLTabFormer model. The left block shows the non-relational tabular data model using GPT-2 with a causal LM head. In contrast, the right block shows how a relational dataset's child table is modeled using a sequence-to-sequence (Seq2Seq) model. The Seq2Seq model uses the observations in the parent table to condition the generation of the observations in the child table. The trained GPT-2 model on the parent table, with weights frozen, is also used as the encoder in the Seq2Seq model.\",\n",
    "    \"Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility.\",\n",
    "    \"As the economies of Southeast Asia continue adopting digital technologies, policy makers increasingly ask how to prepare the workforce for emerging labor demands. However, little is known about the skills that workers need to adapt to these changes\"\n",
    "]\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = get_embedding(texts, mode=\"sentence\")\n",
    "\n",
    "# Compute cosine-similarity for each pair of sentences\n",
    "scores = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "print(scores.cpu().numpy())\n",
    "\n",
    "# Test the retrieval performance.\n",
    "query = get_embedding(\"Which sentence talks about concept on jobs?\", mode=\"query\")\n",
    "\n",
    "scores = F.cosine_similarity(query, embeddings, dim=-1)\n",
    "print(scores.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.6846288  0.61258197]\n",
      " [0.6846288  1.0000001  0.65577286]\n",
      " [0.61258197 0.65577286 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "revision = None  # Replace with the specific revision to ensure reproducibility if the model is updated.\n",
    "\n",
    "model = SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\", revision=revision)\n",
    "\n",
    "texts = [\n",
    "    \"Illustration of the REaLTabFormer model. The left block shows the non-relational tabular data model using GPT-2 with a causal LM head. In contrast, the right block shows how a relational dataset's child table is modeled using a sequence-to-sequence (Seq2Seq) model. The Seq2Seq model uses the observations in the parent table to condition the generation of the observations in the child table. The trained GPT-2 model on the parent table, with weights frozen, is also used as the encoder in the Seq2Seq model.\",\n",
    "    \"Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility.\",\n",
    "    \"As the economies of Southeast Asia continue adopting digital technologies, policy makers increasingly ask how to prepare the workforce for emerging labor demands. However, little is known about the skills that workers need to adapt to these changes\",\n",
    "]\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine-similarity for each pair of sentences\n",
    "scores = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "\n",
    "print(scores.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: tensor([[0.7920, 0.6369, 0.1651, 0.3621]])\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "\n",
    "# For retrieval you need to pass this prompt. Please find our more in our blog post.\n",
    "def transform_query(query: str) -> str:\n",
    "    \"\"\"For retrieval, add the prompt for query (not for documents).\"\"\"\n",
    "    return f\"Represent this sentence for searching relevant passages: {query}\"\n",
    "\n",
    "\n",
    "# The model works really well with cls pooling (default) but also with mean pooling.\n",
    "def pooling(outputs: torch.Tensor, inputs: Dict, strategy: str = \"cls\") -> np.ndarray:\n",
    "    if strategy == \"cls\":\n",
    "        outputs = outputs[:, 0]\n",
    "    elif strategy == \"mean\":\n",
    "        outputs = torch.sum(\n",
    "            outputs * inputs[\"attention_mask\"][:, :, None], dim=1\n",
    "        ) / torch.sum(inputs[\"attention_mask\"])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return outputs.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\n",
    "            \"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "# 1. load model\n",
    "model_id = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id).to(mps_device)\n",
    "\n",
    "\n",
    "docs = [\n",
    "    transform_query(\"A man is eating a piece of bread\"),\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating pasta.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "]\n",
    "\n",
    "# 2. encode\n",
    "inputs = tokenizer(docs, padding=True, return_tensors=\"pt\")\n",
    "for k, v in inputs.items():\n",
    "    inputs[k] = v.to(mps_device)\n",
    "outputs = model(**inputs).last_hidden_state\n",
    "embeddings = pooling(outputs, inputs, \"cls\")\n",
    "\n",
    "similarities = cos_sim(embeddings[0], embeddings[1:])\n",
    "print(\"similarities:\", similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-2.0277e-04,  8.1480e-02,  3.1362e-02,  2.9206e-03,  2.6156e-02,\n",
      "          2.9074e-02,  7.8262e-02, -1.8042e-03,  1.0134e-01, -4.5171e-02,\n",
      "          5.8435e-02, -1.5320e-02,  5.4996e-02, -9.8643e-02, -3.5025e-02,\n",
      "          8.4568e-03,  1.5861e-02,  1.0563e-02, -3.4271e-02, -4.7506e-03,\n",
      "          9.9902e-02, -2.0602e-02, -4.4784e-02,  3.1214e-02, -1.1924e-02,\n",
      "         -5.1502e-02, -1.3361e-02,  1.8962e-02,  9.7681e-02, -5.4411e-02,\n",
      "         -3.4331e-02,  8.1291e-02,  4.8812e-02, -1.1028e-02,  2.1352e-02,\n",
      "          1.2719e-02, -1.4397e-02,  3.6287e-02, -7.6123e-02,  3.2329e-02,\n",
      "          2.0810e-02, -4.2202e-02,  9.1291e-02,  2.0853e-02, -3.0802e-02,\n",
      "         -8.3851e-02,  1.3089e-02, -3.0063e-02,  4.1123e-02, -1.2750e-01,\n",
      "         -7.7803e-02, -3.9341e-02,  1.5259e-03, -2.8011e-02,  3.4166e-02,\n",
      "          1.4671e-02, -7.7165e-02,  1.6362e-01,  4.1130e-02, -5.2446e-02,\n",
      "         -4.1877e-02,  1.8053e-02, -1.3892e-02, -3.6819e-02,  6.9498e-02,\n",
      "         -2.5709e-02,  3.5855e-02,  2.1019e-02, -3.8845e-02,  5.4894e-03,\n",
      "         -5.2454e-02,  2.5310e-02, -3.3734e-02,  1.3260e-01, -6.1091e-02,\n",
      "          3.2604e-02,  5.7724e-02, -2.3485e-02,  2.1315e-02, -1.9393e-04,\n",
      "         -6.7914e-03, -9.2327e-02,  8.6956e-03,  4.6764e-02, -1.0960e-02,\n",
      "          3.9058e-02,  4.6745e-02, -6.9786e-02, -8.7696e-03, -4.9557e-03,\n",
      "         -4.6013e-03, -1.3325e-02,  2.3268e-02, -3.5346e-02,  4.8449e-03,\n",
      "          1.1384e-02, -1.2826e-02, -6.8646e-02,  9.0570e-02,  1.4658e-01,\n",
      "         -2.5708e-03,  1.9661e-03, -4.4464e-02,  8.9292e-02, -1.8447e-03,\n",
      "         -7.3945e-02,  2.7054e-02, -1.6221e-02, -6.7888e-03,  5.0310e-03,\n",
      "          2.8731e-03,  1.0946e-01,  5.2623e-03, -2.6717e-02,  2.4029e-02,\n",
      "         -1.0200e-01, -5.5133e-02,  3.1116e-02, -4.2566e-02,  2.4117e-02,\n",
      "          8.6225e-02,  1.4062e-02,  5.4398e-02,  6.5821e-03, -6.5458e-03,\n",
      "         -1.8252e-01,  3.3347e-03, -3.5597e-02,  7.0852e-02, -9.5739e-02,\n",
      "         -1.9637e-02, -3.8111e-02, -3.3517e-02, -1.2258e-02, -1.9562e-02,\n",
      "         -1.8821e-02,  7.0906e-02, -2.3828e-02, -4.3826e-02,  4.1404e-03,\n",
      "          2.3493e-02,  7.0897e-02,  4.7444e-02,  1.1003e-01, -1.4624e-02,\n",
      "          8.3857e-02, -2.4992e-02,  2.4340e-02,  2.5843e-02,  3.4867e-03,\n",
      "          7.7577e-02,  1.3686e-02, -1.1243e-03, -4.0977e-02,  9.4303e-03,\n",
      "          8.8913e-02,  1.7867e-02, -1.2560e-02,  2.0347e-02,  2.6828e-02,\n",
      "         -1.1238e-01, -4.3561e-03, -3.5928e-02,  3.5934e-03,  3.4327e-02,\n",
      "         -5.9771e-02, -1.5273e-02,  1.9603e-02, -1.8184e-02,  2.4307e-02,\n",
      "          3.6186e-02,  1.4060e-02,  7.6398e-02, -2.2979e-02, -3.0206e-02,\n",
      "         -5.1809e-02,  8.7022e-03,  1.0374e-02,  2.1267e-02,  1.4750e-02,\n",
      "          1.9905e-02, -3.2679e-02, -5.5886e-02,  1.3337e-02, -2.5530e-02,\n",
      "          2.4946e-02, -2.1107e-02, -9.4090e-03,  6.4730e-02,  8.3395e-02,\n",
      "         -6.2127e-02, -1.8043e-02, -1.3113e-02,  5.5395e-03,  8.6744e-03,\n",
      "         -4.6162e-02,  2.9396e-02,  1.2284e-02,  2.9066e-02, -2.4620e-02,\n",
      "         -3.5201e-02,  4.1181e-02, -5.1175e-02, -7.2992e-02, -4.1523e-02,\n",
      "         -2.8216e-02,  2.1841e-02, -2.0928e-02, -7.1991e-02, -6.3535e-02,\n",
      "          2.9739e-02,  8.8681e-02, -1.2057e-01,  6.4130e-03, -1.4459e-02,\n",
      "          2.0246e-03,  2.1488e-02,  4.1197e-02, -9.9740e-02, -3.5870e-03,\n",
      "         -3.1988e-02, -8.8822e-02,  1.0366e-02,  1.4272e-32, -6.8385e-02,\n",
      "          9.5183e-02, -6.6033e-02, -1.3888e-03,  2.5154e-02, -1.4938e-02,\n",
      "          2.0573e-02,  9.6137e-03, -5.1258e-02,  2.0013e-02, -6.8329e-02,\n",
      "          7.2115e-02,  1.0044e-03,  5.3354e-02, -6.6384e-02, -4.9683e-02,\n",
      "          6.0901e-03,  5.8269e-02, -1.7934e-02,  1.6042e-02,  2.4677e-03,\n",
      "          1.0990e-01, -6.0473e-02,  3.4910e-02,  8.8677e-03,  5.3823e-02,\n",
      "          3.7571e-02, -4.1250e-02, -9.2934e-02, -2.5795e-02, -2.7331e-02,\n",
      "         -3.4021e-03, -5.4225e-02,  8.9704e-02, -3.5219e-02,  2.8063e-02,\n",
      "          1.0967e-01, -8.7929e-02, -2.8320e-02, -1.2708e-02, -7.5368e-02,\n",
      "         -6.2295e-02, -1.0085e-01,  1.6844e-01, -6.5540e-02, -2.0168e-02,\n",
      "          2.0491e-02, -5.0510e-03,  3.5321e-02,  1.8797e-02, -8.6906e-02,\n",
      "         -4.4078e-02,  3.2455e-02,  3.7313e-03, -4.6977e-02, -6.9930e-03,\n",
      "         -1.1259e-02, -3.0085e-02,  2.6413e-02, -2.5476e-02, -9.4452e-02,\n",
      "          4.4760e-02,  2.5994e-02,  3.3665e-02,  1.0736e-01,  2.3867e-02,\n",
      "         -5.2156e-02, -2.5788e-02, -8.8480e-03, -4.3215e-02, -5.7881e-02,\n",
      "         -5.8849e-03, -4.2223e-02,  1.2516e-02,  1.2976e-02,  1.6190e-02,\n",
      "         -2.0928e-02, -8.6367e-02, -5.2927e-02, -9.7199e-04,  5.2095e-02,\n",
      "         -1.6528e-02,  6.2263e-02, -4.5417e-03,  2.8057e-02,  1.7149e-02,\n",
      "         -4.0357e-02,  1.9064e-02, -1.7533e-02,  4.1397e-02,  3.0693e-02,\n",
      "         -6.7856e-02,  9.4663e-02,  6.1527e-02, -2.6196e-02,  1.3921e-32,\n",
      "          1.4822e-02, -1.5217e-01,  2.2513e-02,  2.2708e-02,  9.2292e-02,\n",
      "         -2.1752e-04,  6.1387e-02, -7.1298e-02, -3.9596e-02, -9.7091e-03,\n",
      "         -6.7820e-02,  3.6662e-03, -2.5306e-02,  9.2944e-02,  1.6062e-02,\n",
      "          1.1275e-01,  7.1875e-03, -2.6517e-04, -9.7104e-02,  2.0065e-03,\n",
      "          5.1454e-02,  1.5657e-03, -8.6278e-02, -7.9789e-03,  2.0431e-02,\n",
      "          8.4077e-03, -7.0003e-02,  2.1912e-02, -1.6641e-02,  2.1762e-02,\n",
      "          2.4746e-02,  8.9329e-02,  3.6120e-02, -5.7498e-02,  9.1585e-03,\n",
      "          1.2512e-02,  6.6342e-02, -5.7440e-02,  2.8195e-02, -6.7379e-02,\n",
      "         -2.0346e-02,  4.7499e-02,  9.1575e-03,  8.0042e-02,  5.6499e-02,\n",
      "          6.3730e-02, -1.9476e-02,  5.6837e-03,  2.9342e-02, -3.6142e-02,\n",
      "          4.4897e-02, -4.1797e-02,  5.8553e-02, -1.5352e-03,  3.3426e-02,\n",
      "         -3.7150e-02,  9.1379e-02,  4.6740e-03, -1.4017e-02,  2.1975e-02,\n",
      "          2.3849e-02,  6.2093e-02,  4.9103e-02, -2.9020e-04],\n",
      "        [ 6.4757e-02,  4.8520e-02, -1.7860e-02, -4.7978e-02, -5.9088e-02,\n",
      "         -5.2142e-02,  3.9443e-02, -6.2844e-02,  6.6121e-02,  7.6580e-02,\n",
      "         -2.1248e-04,  1.5320e-02,  3.9968e-02, -7.0601e-02,  2.4244e-02,\n",
      "         -4.1588e-02, -1.4465e-03, -7.7605e-03, -5.6043e-02, -8.8963e-02,\n",
      "          7.0695e-02,  2.1028e-02,  2.8623e-02, -7.8708e-03, -1.6565e-02,\n",
      "          7.3264e-02, -9.4989e-02,  1.3173e-02, -7.2403e-03, -5.3078e-02,\n",
      "          1.8276e-02,  8.4790e-02,  2.0148e-02, -5.9290e-03,  2.0633e-02,\n",
      "         -2.2634e-02, -5.8569e-02, -2.3669e-02,  4.6745e-03, -2.8571e-02,\n",
      "          4.1322e-02,  3.8646e-02,  3.7961e-02, -7.8516e-04,  4.3212e-02,\n",
      "         -6.8687e-03, -7.1445e-02, -1.3836e-02,  6.3514e-02, -3.9610e-02,\n",
      "         -9.4036e-02, -2.8578e-02, -5.9751e-02,  4.5022e-02, -6.7160e-03,\n",
      "         -6.9539e-02, -1.7032e-02,  1.4767e-01,  8.3853e-03, -6.9842e-02,\n",
      "         -9.5375e-02,  6.2728e-02,  5.6312e-03,  9.3423e-04,  4.2998e-02,\n",
      "         -2.3814e-02,  1.7499e-02, -4.1666e-02, -9.1068e-02,  4.0324e-02,\n",
      "         -5.2188e-02, -1.3495e-02, -8.4515e-02,  1.5438e-02, -5.9344e-03,\n",
      "         -5.4702e-02,  5.3660e-02, -3.3120e-02,  3.2658e-02,  3.9698e-03,\n",
      "          3.1456e-02, -7.8030e-02, -2.3606e-02, -4.9058e-02,  1.3479e-02,\n",
      "         -1.4947e-02,  1.0118e-03,  1.3985e-02, -3.9593e-02,  5.1760e-03,\n",
      "         -4.1498e-02, -7.5046e-02,  5.3408e-02,  2.3429e-02, -9.2004e-05,\n",
      "          5.9118e-02,  6.0022e-03, -1.8379e-02,  1.0178e-01,  1.6152e-01,\n",
      "         -3.0536e-02,  3.3435e-02,  4.7782e-02, -7.9538e-02, -8.6922e-02,\n",
      "         -6.1917e-02,  3.8695e-02,  1.1651e-02,  8.7407e-03, -1.3770e-02,\n",
      "         -1.7931e-03,  1.6942e-02,  4.2991e-02,  2.1575e-02, -8.6346e-03,\n",
      "         -3.0008e-02, -1.5688e-02, -2.4927e-02, -1.0175e-01,  1.1502e-01,\n",
      "          5.3017e-02,  6.1178e-02, -2.1013e-02,  1.5198e-02,  1.5468e-02,\n",
      "         -1.3327e-01,  4.2989e-02, -1.0496e-02,  4.3588e-02,  1.4730e-02,\n",
      "          1.6897e-02,  1.8899e-02, -8.4391e-02, -4.1344e-02, -8.0098e-03,\n",
      "         -2.5796e-02, -1.5376e-02,  4.5267e-02, -2.4526e-02, -5.1237e-02,\n",
      "          4.2822e-02,  7.4222e-02, -9.3769e-02,  6.7627e-02, -2.8599e-02,\n",
      "          8.1742e-02, -6.8643e-02, -3.6141e-02,  2.3759e-02,  7.5191e-02,\n",
      "          2.6129e-03,  1.0520e-02, -6.7882e-02,  6.1898e-04,  3.1989e-02,\n",
      "          1.6200e-02, -1.3205e-02, -9.0472e-02,  1.8151e-02, -2.3106e-02,\n",
      "         -2.0236e-02,  9.2012e-02,  3.0936e-02, -1.7037e-02,  1.4810e-01,\n",
      "          1.8567e-02, -1.4637e-02,  1.4305e-02, -1.0724e-01, -1.8698e-02,\n",
      "          8.3791e-02, -3.9420e-02,  2.4687e-02,  6.7460e-02,  5.2701e-02,\n",
      "          3.0487e-03,  5.5075e-02, -2.9316e-02,  9.9098e-03, -7.4482e-02,\n",
      "          4.8238e-03, -3.1327e-03,  6.5845e-02,  2.5837e-02,  2.5481e-02,\n",
      "         -8.7161e-03, -1.3477e-03,  1.9123e-02,  2.8082e-02,  3.6589e-02,\n",
      "         -2.4493e-02, -8.0808e-02,  2.4913e-02, -5.3329e-03, -1.7102e-02,\n",
      "          3.3867e-02,  6.3400e-02, -3.3917e-03, -6.7354e-02, -5.5938e-03,\n",
      "          2.1498e-02,  6.5722e-02, -4.7381e-02, -7.9362e-02,  4.1011e-02,\n",
      "         -4.6011e-02, -6.3487e-03, -1.1641e-01, -1.7334e-02,  1.8094e-02,\n",
      "          3.6837e-02,  4.4314e-02, -3.6483e-02,  8.4557e-02, -9.2859e-03,\n",
      "          1.4072e-02,  3.9822e-02, -1.7269e-02,  4.2461e-02, -8.4236e-02,\n",
      "         -9.0057e-02, -1.0825e-01,  5.1165e-02, -6.6264e-34,  1.0048e-02,\n",
      "          1.4766e-01, -1.2518e-01,  1.3070e-02, -7.7228e-02, -4.0407e-02,\n",
      "         -2.2849e-04,  3.9996e-02,  2.8852e-02, -7.1699e-02,  5.1952e-02,\n",
      "         -1.1209e-02, -4.2056e-02,  1.6541e-02, -4.6489e-03, -6.9046e-02,\n",
      "          8.3360e-02,  1.3289e-01,  1.7192e-02, -3.9012e-02,  5.0294e-04,\n",
      "          5.8492e-02, -1.9177e-02,  4.0329e-02, -1.1858e-01, -2.2612e-02,\n",
      "          4.3220e-02,  3.7335e-04, -2.6073e-02,  7.5084e-03,  2.6288e-02,\n",
      "         -9.5066e-03, -3.0889e-02,  8.5365e-02, -7.8631e-02,  5.0378e-03,\n",
      "          1.0590e-02, -5.0390e-02, -3.7519e-02,  1.0257e-01, -1.0085e-02,\n",
      "         -1.9220e-02, -9.5136e-02,  4.9900e-02, -4.5786e-02, -2.0724e-02,\n",
      "          6.8227e-03, -1.0297e-02,  2.7976e-02, -9.2418e-02,  5.9145e-02,\n",
      "         -6.7858e-02, -1.6361e-02, -5.3730e-02,  2.5811e-02, -3.9608e-02,\n",
      "         -1.3228e-02, -8.0786e-02,  3.2411e-02, -1.1777e-02, -5.6467e-02,\n",
      "          2.8093e-02,  1.3829e-02, -6.2383e-03,  3.3643e-02,  6.1135e-02,\n",
      "          1.8746e-02,  8.0135e-02,  4.9136e-02, -1.7234e-02,  9.3471e-03,\n",
      "         -1.3336e-02, -1.3108e-02,  4.1614e-03, -5.4686e-03, -9.3124e-02,\n",
      "         -4.0893e-02, -2.4925e-02, -5.9402e-02, -3.1374e-02,  5.2622e-02,\n",
      "         -5.0378e-02,  2.7204e-02,  2.3029e-02,  2.6585e-02, -2.2152e-02,\n",
      "          8.5036e-02,  6.2771e-02, -2.5475e-02,  4.6020e-02, -1.1727e-02,\n",
      "          4.5752e-02,  7.5289e-02,  2.2162e-02, -9.4697e-03,  2.6075e-32,\n",
      "         -4.3285e-02, -6.5349e-02, -1.4460e-01,  2.5365e-02,  8.4028e-02,\n",
      "         -7.9134e-03,  3.1147e-02, -1.2550e-01, -2.0570e-02, -2.6311e-02,\n",
      "          2.4025e-02,  3.1844e-02, -5.1213e-02,  5.7909e-02,  9.6493e-03,\n",
      "          6.7943e-02,  1.1691e-03,  1.9395e-02, -1.3452e-02,  3.5442e-02,\n",
      "         -3.8499e-02, -1.4651e-02, -2.8915e-02, -3.0350e-02, -2.8647e-02,\n",
      "          2.8942e-02, -1.1235e-02,  4.1892e-03,  5.2143e-02,  7.4088e-04,\n",
      "          3.0334e-02,  5.1220e-02, -2.3024e-02, -5.6751e-02, -2.7655e-02,\n",
      "         -5.0641e-02,  7.3886e-02,  3.7308e-02,  9.6625e-02, -1.1150e-02,\n",
      "          1.3744e-02, -1.0921e-02, -6.5581e-03,  6.8877e-03, -6.5519e-02,\n",
      "          6.8194e-04,  1.5204e-02,  1.5714e-02,  2.2339e-02, -4.5054e-02,\n",
      "          3.9938e-02, -5.9020e-02,  5.9023e-02, -5.9431e-02,  6.6442e-02,\n",
      "         -5.4190e-02, -1.8829e-02,  1.1727e-01,  8.4973e-03,  1.0795e-01,\n",
      "         -7.0660e-04,  3.3757e-02,  8.4337e-03, -6.0036e-02]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag--zl4sBlN-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
