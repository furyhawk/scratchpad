<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>rag - 124c41</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "rag";
        var mkdocs_page_input_path = "rag.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> 124c41
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../resume/">Resume</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../conda/">Conda</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../git/">git</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../softwarearchitecture/">softwarearchitecture</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../code/">vscode</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../machine_learning/">machine_learning</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../llm/">llm</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">rag</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#huggingface">Huggingface</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#langchain">langchain</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../llama2/">llmama2</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../framework/">Framework</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../db/">database</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../dataframe/">Dataframe</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../anomaly_detection/">anomaly_detection</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../chart/">Chart</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../hydra/">Hydra</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../linux/">Linux</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../macos/">macos</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../sway/">sway</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../docker/">Docker</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../jetson/">jetson</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../yolox/">yolox</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../gpt/">gpt</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stable_diffusion/">stable_diffussion</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../wandb/">Model Analysis</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ssh/">ssh</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../smb/">Samba</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../smb2/">Samba_ubuntu</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../mkdocs/">MkDocs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../mypy/">mypy</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../literatures/">Literatures</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../scrape_pad/">scrape_pad</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../random/">random</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../about/">About</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">124c41</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>rag</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="rag">RAG</h1>
<h2 id="huggingface">Huggingface</h2>
<p>Retriever used to get documents from vector queries. It retrieves the documents embeddings as well as the documents contents, and it formats them to be used with a RagModel.</p>
<p>Examples:</p>
<pre><code class="language-python"># To load the default &quot;wiki_dpr&quot; dataset with 21M passages from wikipedia (index name is 'compressed' or 'exact')
from transformers import RagRetriever

retriever = RagRetriever.from_pretrained(
    &quot;facebook/dpr-ctx_encoder-single-nq-base&quot;, dataset=&quot;wiki_dpr&quot;, index_name=&quot;compressed&quot;
)

# To load your own indexed dataset built with the datasets library. More info on how to build the indexed dataset in examples/rag/use_own_knowledge_dataset.py
from transformers import RagRetriever

dataset = (
    ...
)  # dataset must be a datasets.Datasets object with columns &quot;title&quot;, &quot;text&quot; and &quot;embeddings&quot;, and it must have a faiss index
retriever = RagRetriever.from_pretrained(&quot;facebook/dpr-ctx_encoder-single-nq-base&quot;, indexed_dataset=dataset)

# To load your own indexed dataset built with the datasets library that was saved on disk. More info in examples/rag/use_own_knowledge_dataset.py
from transformers import RagRetriever

dataset_path = &quot;path/to/my/dataset&quot;  # dataset saved via *dataset.save_to_disk(...)*
index_path = &quot;path/to/my/index.faiss&quot;  # faiss index saved via *dataset.get_index(&quot;embeddings&quot;).save(...)*
retriever = RagRetriever.from_pretrained(
    &quot;facebook/dpr-ctx_encoder-single-nq-base&quot;,
    index_name=&quot;custom&quot;,
    passages_path=dataset_path,
    index_path=index_path,
)

# To load the legacy index built originally for Rag's paper
from transformers import RagRetriever

retriever = RagRetriever.from_pretrained(&quot;facebook/dpr-ctx_encoder-single-nq-base&quot;, index_name=&quot;legacy&quot;)
</code></pre>
<p>RAG is a seq2seq model which encapsulates two core components: a question encoder and a generator. During a forward pass, we encode the input with the question encoder and pass it to the retriever to extract relevant context documents. The documents are then prepended to the input. Such contextualized inputs is passed to the generator.</p>
<pre><code class="language-python">from transformers import AutoTokenizer, RagRetriever, RagModel
import torch

tokenizer = AutoTokenizer.from_pretrained(&quot;facebook/rag-token-base&quot;)
retriever = RagRetriever.from_pretrained(
    &quot;facebook/rag-token-base&quot;, index_name=&quot;exact&quot;, use_dummy_dataset=True
)
# initialize with RagRetriever to do everything in one forward call
model = RagModel.from_pretrained(&quot;facebook/rag-token-base&quot;, retriever=retriever)

inputs = tokenizer(&quot;How many people live in Paris?&quot;, return_tensors=&quot;pt&quot;)
outputs = model(input_ids=inputs[&quot;input_ids&quot;])
</code></pre>
<pre><code class="language-python">from transformers import AutoTokenizer, RagRetriever, RagSequenceForGeneration
import torch

tokenizer = AutoTokenizer.from_pretrained(&quot;facebook/rag-sequence-nq&quot;)
retriever = RagRetriever.from_pretrained(
    &quot;facebook/rag-sequence-nq&quot;, index_name=&quot;exact&quot;, use_dummy_dataset=True
)
# initialize with RagRetriever to do everything in one forward call
model = RagSequenceForGeneration.from_pretrained(&quot;facebook/rag-token-nq&quot;, retriever=retriever)

inputs = tokenizer(&quot;How many people live in Paris?&quot;, return_tensors=&quot;pt&quot;)
targets = tokenizer(text_target=&quot;In Paris, there are 10 million people.&quot;, return_tensors=&quot;pt&quot;)
input_ids = inputs[&quot;input_ids&quot;]
labels = targets[&quot;input_ids&quot;]
outputs = model(input_ids=input_ids, labels=labels)

# or use retriever separately
model = RagSequenceForGeneration.from_pretrained(&quot;facebook/rag-sequence-nq&quot;, use_dummy_dataset=True)
# 1. Encode
question_hidden_states = model.question_encoder(input_ids)[0]
# 2. Retrieve
docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=&quot;pt&quot;)
doc_scores = torch.bmm(
    question_hidden_states.unsqueeze(1), docs_dict[&quot;retrieved_doc_embeds&quot;].float().transpose(1, 2)
).squeeze(1)
# 3. Forward to generator
outputs = model(
    context_input_ids=docs_dict[&quot;context_input_ids&quot;],
    context_attention_mask=docs_dict[&quot;context_attention_mask&quot;],
    doc_scores=doc_scores,
    decoder_input_ids=labels,
)
</code></pre>
<h2 id="langchain">langchain</h2>
<p>https://python.langchain.com/docs/expression_language/cookbook/retrieval</p>
<p>Let's look at adding in a retrieval step to a prompt and LLM, which adds up to a "retrieval-augmented generation" chain</p>
<pre><code class="language-sh">pip install langchain openai faiss-cpu tiktoken
``````

```python
from operator import itemgetter

from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough
from langchain.vectorstores import FAISS

vectorstore = FAISS.from_texts([&quot;harrison worked at kensho&quot;], embedding=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

template = &quot;&quot;&quot;Answer the question based only on the following context:
{context}

Question: {question}
&quot;&quot;&quot;
prompt = ChatPromptTemplate.from_template(template)

model = ChatOpenAI()

chain = (
    {&quot;context&quot;: retriever, &quot;question&quot;: RunnablePassthrough()} 
    | prompt 
    | model 
    | StrOutputParser()
)
chain.invoke(&quot;where did harrison work?&quot;)

template = &quot;&quot;&quot;Answer the question based only on the following context:
{context}

Question: {question}

Answer in the following language: {language}
&quot;&quot;&quot;
prompt = ChatPromptTemplate.from_template(template)

chain = {
    &quot;context&quot;: itemgetter(&quot;question&quot;) | retriever, 
    &quot;question&quot;: itemgetter(&quot;question&quot;), 
    &quot;language&quot;: itemgetter(&quot;language&quot;)
} | prompt | model | StrOutputParser()

chain.invoke({&quot;question&quot;: &quot;where did harrison work&quot;, &quot;language&quot;: &quot;italian&quot;})



</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../llm/" class="btn btn-neutral float-left" title="llm"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../llama2/" class="btn btn-neutral float-right" title="llmama2">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../llm/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../llama2/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
