{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:03:30.251409Z","iopub.status.busy":"2023-03-12T05:03:30.250383Z","iopub.status.idle":"2023-03-12T05:03:32.774923Z","shell.execute_reply":"2023-03-12T05:03:32.773902Z","shell.execute_reply.started":"2023-03-12T05:03:30.251369Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import glob\n","import json\n","from collections import defaultdict\n","import multiprocessing as mp\n","from pathlib import Path\n","from types import SimpleNamespace\n","from typing import Dict, List, Optional, Tuple\n","import warnings\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import numpy as np\n","import pandas as pd\n","import PIL.Image as Image\n","from sklearn.metrics import f1_score\n","from sklearn.exceptions import UndefinedMetricWarning\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as thd\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["### Set up data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:03:35.226939Z","iopub.status.busy":"2023-03-12T05:03:35.22639Z","iopub.status.idle":"2023-03-12T05:03:35.253948Z","shell.execute_reply":"2023-03-12T05:03:35.252527Z","shell.execute_reply.started":"2023-03-12T05:03:35.226888Z"},"trusted":true},"outputs":[],"source":["class SubvolumeDataset(thd.Dataset):\n","    def __init__(\n","        self,\n","        fragments: List[Path],\n","        voxel_shape: Tuple[int, int, int],\n","        load_inklabels: bool = True,\n","        filter_edge_pixels: bool = False,\n","    ):\n","        self.fragments = sorted(map(lambda path: path.resolve(), fragments))\n","        self.voxel_shape = voxel_shape\n","        self.load_inklabels = load_inklabels\n","        self.filter_edge_pixels = filter_edge_pixels\n","\n","        # Load sequentially\n","        labels = []\n","        image_stacks = []\n","        valid_pixels = []\n","        for fragment_id, fragment_path in enumerate(self.fragments):\n","            fragment_path = fragment_path.resolve()  # absolute path\n","            mask = np.array(Image.open(str(fragment_path / \"mask.png\")).convert(\"1\"))\n","\n","            surface_volume_paths = sorted(\n","                (fragment_path / \"surface_volume\").rglob(\"*.tif\")\n","            )\n","            z_dim, y_dim, x_dim = voxel_shape\n","\n","            z_mid = len(surface_volume_paths) // 2\n","            z_start, z_end = z_mid - z_dim // 2, z_mid + z_dim // 2\n","\n","            # we don't convert to torch since it doesn't support uint16\n","            images = [\n","                np.array(Image.open(fn)) for fn in surface_volume_paths[z_start:z_end]\n","            ]\n","            image_stack = np.stack(images, axis=0)\n","            image_stacks.append(image_stack)\n","\n","            pixels = np.stack(np.where(mask == 1), axis=1).astype(np.uint16)\n","            if filter_edge_pixels:\n","                height, width = mask.shape\n","                mask_y = np.logical_or(\n","                    pixels[:, 0] < y_dim // 2, pixels[:, 0] >= height - y_dim // 2\n","                )\n","                mask_x = np.logical_or(\n","                    pixels[:, 1] < x_dim // 2, pixels[:, 1] >= width - x_dim // 2\n","                )\n","                pixel_mask = np.logical_or(mask_y, mask_x)\n","                pixels = pixels[~pixel_mask]\n","            # encode fragment ID\n","            fragment_ids = np.full_like(pixels[:, 0:1], fragment_id)\n","            pixels = np.concatenate((pixels, fragment_ids), axis=1)\n","            valid_pixels.append(pixels)\n","\n","            if load_inklabels:\n","                # binary mask can be stored as np.bool\n","                inklabels = (\n","                    np.array(Image.open(str(fragment_path / \"inklabels.png\"))) > 0\n","                )\n","                labels.append(inklabels)\n","\n","            print(f\"Loaded fragment {fragment_path} on {os.getpid()}\")\n","\n","        self.labels = labels\n","        self.image_stacks = image_stacks\n","        self.pixels = np.concatenate(valid_pixels).reshape(\n","            -1, valid_pixels[0].shape[-1]\n","        )\n","\n","    def __len__(self):\n","        return len(self.pixels)\n","\n","    def __getitem__(self, index):\n","        center_y, center_x, fragment_id = self.pixels[index]\n","        z_dim, y_dim, x_dim = self.voxel_shape\n","        image_stack = self.image_stacks[fragment_id]\n","        _, height, width = image_stack.shape\n","\n","        # pad with zeros if necessary\n","        if (\n","            center_y < y_dim // 2\n","            or center_x < x_dim // 2\n","            or center_y + y_dim // 2 >= height\n","            or center_x + x_dim // 2 >= width\n","        ):\n","            # calculate the upper-left corner of the sub-volume\n","            y_start = max(center_y - y_dim // 2, 0)\n","            x_start = max(center_x - x_dim // 2, 0)\n","\n","            # calculate the lower-right corner of the sub-volume\n","            y_end = min(center_y + y_dim // 2, height)\n","            x_end = min(center_x + x_dim // 2, width)\n","\n","            subvolume = np.zeros(self.voxel_shape, dtype=np.float32)\n","\n","            pad_y_start = max(y_dim // 2 - center_y, 0)\n","            pad_x_start = max(x_dim // 2 - center_x, 0)\n","\n","            pad_y_end = min(height + y_dim // 2 - center_y, y_dim)\n","            pad_x_end = min(width + x_dim // 2 - center_x, x_dim)\n","\n","            subvolume[:, pad_y_start:pad_y_end, pad_x_start:pad_x_end] = (\n","                image_stack[:, y_start:y_end, x_start:x_end].astype(np.float32) / 65535\n","            )\n","\n","        else:\n","            subvolume = (\n","                image_stack[\n","                    :,\n","                    center_y - y_dim // 2 : center_y + y_dim // 2,\n","                    center_x - x_dim // 2 : center_x + x_dim // 2,\n","                ]\n","            ).astype(np.float32) / 65535\n","        if self.load_inklabels:\n","            inklabel = float(self.labels[fragment_id][center_y, center_x])\n","        else:\n","            inklabel = -1.0\n","\n","        return torch.from_numpy(subvolume).unsqueeze(0), torch.FloatTensor([inklabel])\n","\n","    def plot_label(self, index, **kwargs):\n","        pixel = self.pixels[index]\n","        label = self.labels[pixel[-1]]\n","\n","        print(\"Index:\", index)\n","        print(\"Pixel:\", pixel)\n","        print(\"Label:\", int(label[pixel[0], pixel[1]]))\n","\n","        if isinstance(label, torch.Tensor):\n","            label = label.numpy()\n","\n","        fig, ax = plt.subplots(**kwargs)\n","        ax.imshow(label, cmap=\"gray\")\n","\n","        y, x, _ = pixel\n","        _, y_dim, x_dim = self.voxel_shape\n","        x_min = x - (x_dim // 2)\n","        x_max = x + (x_dim // 2)\n","        y_min = y - (y_dim // 2)\n","        y_max = y + (y_dim // 2)\n","\n","        rect = plt.Rectangle(\n","            (x_min, y_min), x_dim, y_dim, linewidth=2, edgecolor=\"y\", facecolor=\"none\"\n","        )\n","        ax.add_patch(rect)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:03:36.082781Z","iopub.status.busy":"2023-03-12T05:03:36.080925Z","iopub.status.idle":"2023-03-12T05:03:36.103637Z","shell.execute_reply":"2023-03-12T05:03:36.102599Z","shell.execute_reply.started":"2023-03-12T05:03:36.082722Z"},"trusted":true},"outputs":[],"source":["base_path = Path(\"/kaggle/input/vesuvius-challenge/\")\n","train_path = base_path / \"train\"\n","all_fragments = sorted([f.name for f in train_path.iterdir()])\n","print(\"All fragments:\", all_fragments)\n","# Due to limited memory on Kaggle, we can only load 1 full fragment\n","train_fragments = [train_path / fragment_name for fragment_name in [\"1\"]]\n","train_fragments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:03:37.027575Z","iopub.status.busy":"2023-03-12T05:03:37.027191Z","iopub.status.idle":"2023-03-12T05:05:03.115973Z","shell.execute_reply":"2023-03-12T05:05:03.114754Z","shell.execute_reply.started":"2023-03-12T05:03:37.027543Z"},"trusted":true},"outputs":[],"source":["%%time\n","train_dset = SubvolumeDataset(fragments=train_fragments, voxel_shape=(48, 64, 64), filter_edge_pixels=True)\n","print(\"Num items (pixels)\", len(train_dset))"]},{"cell_type":"markdown","metadata":{},"source":["#### Sanity check "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:05:30.666631Z","iopub.status.busy":"2023-03-12T05:05:30.665586Z","iopub.status.idle":"2023-03-12T05:05:33.617639Z","shell.execute_reply":"2023-03-12T05:05:33.61654Z","shell.execute_reply.started":"2023-03-12T05:05:30.666591Z"},"trusted":true},"outputs":[],"source":["index = 6136130\n","train_dset.plot_label(index, figsize=(16, 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:05:37.721697Z","iopub.status.busy":"2023-03-12T05:05:37.72112Z","iopub.status.idle":"2023-03-12T05:05:37.728779Z","shell.execute_reply":"2023-03-12T05:05:37.727449Z","shell.execute_reply.started":"2023-03-12T05:05:37.721655Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","train_loader = thd.DataLoader(train_dset, batch_size=BATCH_SIZE, shuffle=True)\n","print(\"Num batches:\", len(train_loader))"]},{"cell_type":"markdown","metadata":{},"source":["### Set up model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:05:54.362969Z","iopub.status.busy":"2023-03-12T05:05:54.361908Z","iopub.status.idle":"2023-03-12T05:05:54.42694Z","shell.execute_reply":"2023-03-12T05:05:54.42573Z","shell.execute_reply.started":"2023-03-12T05:05:54.362932Z"},"trusted":true},"outputs":[],"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:05:54.949516Z","iopub.status.busy":"2023-03-12T05:05:54.949137Z","iopub.status.idle":"2023-03-12T05:05:54.958963Z","shell.execute_reply":"2023-03-12T05:05:54.957794Z","shell.execute_reply.started":"2023-03-12T05:05:54.949478Z"},"trusted":true},"outputs":[],"source":["class InkDetector(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        filters = [16, 32, 64]\n","        paddings = [1, 1, 1]\n","        kernel_sizes = [3, 3, 3]\n","        strides = [2, 2, 2]\n","        \n","        layers = []\n","        in_channels = 1\n","        for num_filters, padding, kernel_size, stride in zip(filters, paddings, kernel_sizes, strides):\n","            layers.extend([\n","                nn.Conv3d(\n","                    in_channels=in_channels,\n","                    out_channels=num_filters,\n","                    kernel_size=kernel_size,\n","                    stride=stride,\n","                    padding=padding,\n","                ),\n","                nn.ReLU(inplace=True),\n","                torch.nn.BatchNorm3d(num_features=num_filters)\n","            ])\n","            in_channels = num_filters\n","        layers.append(nn.AdaptiveAvgPool3d(1))\n","        layers.append(nn.Flatten())\n","\n","        self.encoder = nn.Sequential(*layers)\n","        self.decoder = nn.Sequential(\n","            nn.Linear(in_channels, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(128, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, x):\n","        features = self.encoder(x)\n","        return self.decoder(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:05:58.420654Z","iopub.status.busy":"2023-03-12T05:05:58.42029Z","iopub.status.idle":"2023-03-12T05:06:01.070564Z","shell.execute_reply":"2023-03-12T05:06:01.069503Z","shell.execute_reply.started":"2023-03-12T05:05:58.420623Z"},"trusted":true},"outputs":[],"source":["model = InkDetector().to(DEVICE)"]},{"cell_type":"markdown","metadata":{},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:06:03.441686Z","iopub.status.busy":"2023-03-12T05:06:03.441194Z","iopub.status.idle":"2023-03-12T05:06:03.446722Z","shell.execute_reply":"2023-03-12T05:06:03.445521Z","shell.execute_reply.started":"2023-03-12T05:06:03.44164Z"},"trusted":true},"outputs":[],"source":["TRAINING_STEPS = 60000\n","LEARNING_RATE = 1e-3\n","TRAIN_RUN = True # To avoid re-running when saving the notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:46:21.161623Z","iopub.status.busy":"2023-03-12T06:46:21.160717Z","iopub.status.idle":"2023-03-12T06:46:21.165818Z","shell.execute_reply":"2023-03-12T06:46:21.164658Z","shell.execute_reply.started":"2023-03-12T06:46:21.161586Z"},"trusted":true},"outputs":[],"source":["warnings.simplefilter('ignore', UndefinedMetricWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:08:00.458519Z","iopub.status.busy":"2023-03-12T05:08:00.458133Z","iopub.status.idle":"2023-03-12T05:56:18.07033Z","shell.execute_reply":"2023-03-12T05:56:18.069165Z","shell.execute_reply.started":"2023-03-12T05:08:00.458481Z"},"trusted":true},"outputs":[],"source":["if TRAIN_RUN:\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, total_steps=TRAINING_STEPS)\n","    model.train()\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","    running_f1 = 0.0\n","    denom = 0\n","    pbar = tqdm(enumerate(train_loader), total=TRAINING_STEPS)\n","    for i, (subvolumes, inklabels) in pbar:\n","        if i >= TRAINING_STEPS:\n","            break\n","        optimizer.zero_grad()\n","        outputs = model(subvolumes.to(DEVICE))\n","        loss = criterion(outputs, inklabels.to(DEVICE))\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        pred_ink = outputs.detach().sigmoid().gt(0.4).cpu().int()\n","        accuracy = (pred_ink == inklabels).sum().float().div(inklabels.size(0))\n","        running_f1 += f1_score(inklabels.view(-1).numpy(), pred_ink.view(-1).numpy())\n","        running_accuracy += accuracy.item()\n","        running_loss += loss.item()\n","        denom += 1\n","        pbar.set_postfix({\"Loss\": running_loss / denom, \"Accuracy\": running_accuracy / denom, \"F1\": running_f1 / denom})\n","        if (i + 1) % 500 == 0:\n","            running_loss = 0.\n","            running_accuracy = 0.\n","            running_f1 = 0.\n","            denom = 0\n","\n","    torch.save(model.state_dict(), \"/kaggle/working/model.pt\")\n","\n","else:\n","    model_weights = torch.load(\"/kaggle/working/model.pt\")\n","    model.load_state_dict(model_weights)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Clear memory before loading test fragments\n","train_dset.labels = None\n","train_dset.image_stacks = []\n","del train_loader, train_dset\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T05:56:45.592504Z","iopub.status.busy":"2023-03-12T05:56:45.591542Z","iopub.status.idle":"2023-03-12T05:56:45.610137Z","shell.execute_reply":"2023-03-12T05:56:45.60915Z","shell.execute_reply.started":"2023-03-12T05:56:45.592423Z"},"trusted":true},"outputs":[],"source":["test_path = base_path / \"test\"\n","test_fragments = [train_path / fragment_name for fragment_name in test_path.iterdir()]\n","print(\"All fragments:\", test_fragments)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:42:01.349882Z","iopub.status.busy":"2023-03-12T06:42:01.348847Z","iopub.status.idle":"2023-03-12T06:42:06.085811Z","shell.execute_reply":"2023-03-12T06:42:06.084768Z","shell.execute_reply.started":"2023-03-12T06:42:01.349834Z"},"trusted":true},"outputs":[],"source":["pred_images = []\n","model.eval()\n","for test_fragment in test_fragments:\n","    outputs = []\n","    eval_dset = SubvolumeDataset(fragments=[test_fragment], voxel_shape=(48, 64, 64), load_inklabels=False)\n","    eval_loader = thd.DataLoader(eval_dset, batch_size=BATCH_SIZE, shuffle=False)\n","    with torch.no_grad():\n","        for i, (subvolumes, _) in enumerate(tqdm(eval_loader)):\n","            output = model(subvolumes.to(DEVICE)).view(-1).sigmoid().cpu().numpy()\n","            outputs.append(output)\n","    # we only load 1 fragment at a time\n","    image_shape = eval_dset.image_stacks[0].shape[1:]\n","    eval_dset.labels = None\n","    eval_dset.image_stacks = None\n","    del eval_loader\n","    gc.collect()\n","\n","    pred_image = np.zeros(image_shape, dtype=np.uint8)\n","    outputs = np.concatenate(outputs)\n","    for (y, x, _), prob in zip(eval_dset.pixels[:outputs.shape[0]], outputs):\n","        pred_image[y ,x] = prob > 0.4\n","    pred_images.append(pred_image)\n","    \n","    eval_dset.pixels = None\n","    del eval_dset\n","    gc.collect()\n","    print(\"Finished\", test_fragment)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:42:17.30664Z","iopub.status.busy":"2023-03-12T06:42:17.305738Z","iopub.status.idle":"2023-03-12T06:42:17.990385Z","shell.execute_reply":"2023-03-12T06:42:17.989267Z","shell.execute_reply.started":"2023-03-12T06:42:17.306591Z"},"trusted":true},"outputs":[],"source":["plt.imshow(pred_images[1], cmap='gray')"]},{"cell_type":"markdown","metadata":{},"source":["### Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:42:21.288286Z","iopub.status.busy":"2023-03-12T06:42:21.28772Z","iopub.status.idle":"2023-03-12T06:42:21.297229Z","shell.execute_reply":"2023-03-12T06:42:21.296139Z","shell.execute_reply.started":"2023-03-12T06:42:21.288245Z"},"trusted":true},"outputs":[],"source":["def rle(output):\n","    flat_img = np.where(output > 0.4, 1, 0).astype(np.uint8)\n","    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n","    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n","    starts_ix = np.where(starts)[0] + 2\n","    ends_ix = np.where(ends)[0] + 2\n","    lengths = ends_ix - starts_ix\n","    return \" \".join(map(str, sum(zip(starts_ix, lengths), ())))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:43:13.835159Z","iopub.status.busy":"2023-03-12T06:43:13.834801Z","iopub.status.idle":"2023-03-12T06:43:46.718007Z","shell.execute_reply":"2023-03-12T06:43:46.716939Z","shell.execute_reply.started":"2023-03-12T06:43:13.835129Z"},"trusted":true},"outputs":[],"source":["submission = defaultdict(list)\n","for fragment_id, fragment_name in enumerate(test_fragments):\n","    submission[\"Id\"].append(fragment_name.name)\n","    submission[\"Predicted\"].append(rle(pred_images[fragment_id]))\n","\n","pd.DataFrame.from_dict(submission).to_csv(\"/kaggle/working/submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:44:18.809054Z","iopub.status.busy":"2023-03-12T06:44:18.808586Z","iopub.status.idle":"2023-03-12T06:44:18.842048Z","shell.execute_reply":"2023-03-12T06:44:18.840402Z","shell.execute_reply.started":"2023-03-12T06:44:18.809014Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame.from_dict(submission)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
